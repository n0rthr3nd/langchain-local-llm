apiVersion: v1
kind: ConfigMap
metadata:
  name: langchain-config
  namespace: llm-services
  labels:
    app.kubernetes.io/part-of: langchain-ollama
data:
  # Configuración de Ollama
  OLLAMA_BASE_URL: "http://ollama:11434"
  OLLAMA_NUM_PARALLEL: "1"
  OLLAMA_MAX_LOADED_MODELS: "1"

  # Configuración de la API
  MODEL_NAME: "gemma2:2b"
  EMBEDDING_MODEL: "nomic-embed-text"
  PORT: "8000"
  MAX_INPUT_LENGTH: "10000"
  PYTHONUNBUFFERED: "1"

  # Modelos permitidos (separados por coma)
  ALLOWED_MODELS: "gemma2:2b,phi3:mini,llama3.2:3b,tinyllama"
