# üöÄ Despliegue en Kubernetes (k3s)

## Problema: Dropdown de modelos vac√≠o

Si el dropdown de modelos muestra elementos vac√≠os despu√©s de desplegar, es porque el c√≥digo del backend no se actualiz√≥ correctamente.

## ‚úÖ Soluci√≥n R√°pida

### Opci√≥n 1: Rebuild Forzado (Recomendado) ‚ö°

Usa el script que **fuerza reconstrucci√≥n sin cach√©** y **elimina los pods** para garantizar que se usen las nuevas im√°genes:

```bash
cd /home/user/langchain-local-llm
./k8s/scripts/rebuild-force.sh
```

Este script:
1. ‚úÖ Elimina im√°genes viejas localmente
2. ‚úÖ Reconstruye Backend SIN CACHE
3. ‚úÖ Reconstruye Frontend SIN CACHE
4. ‚úÖ Elimina im√°genes viejas de k3s
5. ‚úÖ Importa im√°genes nuevas a k3s
6. ‚úÖ Elimina los pods para forzar recreaci√≥n con nuevas im√°genes
7. ‚úÖ Espera a que los nuevos pods est√©n listos

**Tiempo estimado: 5-10 minutos** (por la reconstrucci√≥n sin cach√©)

---

### Opci√≥n 2: Build + Deploy Normal

Si prefieres usar los scripts normales:

```bash
cd /home/user/langchain-local-llm/k8s/scripts

# 1. Construir e importar im√°genes
./build-and-push.sh

# 2. Desplegar (incluye rollout restart)
./deploy.sh
```

‚ö†Ô∏è **Problema**: Si Docker usa cach√©, los cambios pueden no aplicarse.

---

### Opci√≥n 3: Reinicio Manual de Pods

Si ya ejecutaste build-and-push.sh pero los cambios no se ven:

```bash
# Eliminar pods para forzar recreaci√≥n
kubectl delete pods -n llm-services -l app=langchain-api
kubectl delete pods -n llm-services -l app=langchain-frontend

# Verificar que se recrearon
kubectl get pods -n llm-services -w
```

---

## üîç Verificar que funcion√≥

### 1. Ver los logs del backend

```bash
kubectl logs -n llm-services -l app=langchain-api -f
```

Deber√≠as ver l√≠neas como:
```
DEBUG - Raw Ollama response: ...
DEBUG - Processing model: ...
DEBUG - Extracted name: 'nomic-embed-text:latest'
DEBUG - Processed models: [{'name': 'nomic-embed-text:latest', ...}]
```

### 2. Probar el endpoint desde el navegador

Abre:
```
https://northr3nd.duckdns.org/ia/chat/api/models
```

Deber√≠as ver **objetos**, NO strings:
```json
{
  "models": [
    {
      "name": "nomic-embed-text:latest",
      "size": 274290688,
      "modified_at": "2024-..."
    },
    {
      "name": "gemma2:2b",
      "size": 1628553088,
      "modified_at": "2024-..."
    }
  ]
}
```

‚ùå **Si ves esto, el backend NO se actualiz√≥:**
```json
{"models": ["nomic-embed-text:latest", "gemma2:2b"]}
```

### 3. Probar el dropdown

1. Abre `https://northr3nd.duckdns.org/ia/chat`
2. Haz clic en el bot√≥n de configuraci√≥n (‚öôÔ∏è)
3. El dropdown de "Modelo" deber√≠a mostrar los nombres completos
4. Abre DevTools (F12) ‚Üí Console
5. Deber√≠as ver:
```
DEBUG - ModelSelector received models: [{name: "nomic-embed-text:latest", ...}, ...]
DEBUG - Valid models after filter: [{name: "nomic-embed-text:latest", ...}, ...]
```

---

## üêõ Troubleshooting

### Los cambios a√∫n no se ven despu√©s de rebuild-force.sh

1. **Verificar que las im√°genes se importaron a k3s:**
```bash
sudo ctr -n k8s.io images ls | grep langchain
```

Deber√≠as ver:
```
docker.io/library/langchain-app:latest
docker.io/library/langchain-frontend:latest
```

2. **Verificar que los pods se recrearon:**
```bash
kubectl get pods -n llm-services -o wide
```

Los pods deben tener un AGE reciente (menos de 5 minutos)

3. **Ver logs de errores:**
```bash
# Backend
kubectl logs -n llm-services -l app=langchain-api --tail=100

# Frontend
kubectl logs -n llm-services -l app=langchain-frontend --tail=100
```

### El endpoint /models/raw no funciona

Verifica que el proxy de nginx est√© configurado correctamente:

```bash
kubectl describe ingress -n llm-services
```

---

## üìä Monitoreo

### Ver estado de todos los pods
```bash
kubectl get pods -n llm-services
```

### Ver logs en tiempo real
```bash
# Backend
kubectl logs -n llm-services -l app=langchain-api -f

# Frontend
kubectl logs -n llm-services -l app=langchain-frontend -f

# Ollama
kubectl logs -n llm-services -l app=ollama -f
```

### Ver uso de recursos
```bash
kubectl top pods -n llm-services
```

---

## üßπ Limpieza (Opcional)

Si quieres eliminar todo y volver a empezar:

```bash
cd /home/user/langchain-local-llm/k8s/scripts
./undeploy.sh
```

Luego vuelve a desplegar con `./rebuild-force.sh`

---

## üìù Notas Importantes

- **Siempre usa `rebuild-force.sh`** cuando hagas cambios en el c√≥digo de backend o frontend
- El script normal `build-and-push.sh` + `deploy.sh` puede usar cach√© de Docker y no aplicar los cambios
- Los logs de debug se agregaron espec√≠ficamente para diagnosticar este problema
- Una vez confirmado que funciona, puedes eliminar los logs de debug si quieres reducir el ruido en los logs

---

## üéØ Resumen

**Para aplicar cambios de c√≥digo:**
```bash
./k8s/scripts/rebuild-force.sh
```

**Para verificar:**
```bash
# 1. Ver logs
kubectl logs -n llm-services -l app=langchain-api -f | grep DEBUG

# 2. Probar endpoint
curl https://northr3nd.duckdns.org/ia/chat/api/models

# 3. Abrir navegador y verificar dropdown
```

‚úÖ **El dropdown deber√≠a mostrar los nombres de los modelos correctamente**
