
services:
  # Servicio Ollama - LLM Local
  ollama:
    image: ollama/ollama:latest
    container_name: ollama-server
    ports:
      - "11434:11434"
    volumes:
      # Persistir modelos descargados
      - ollama_data:/root/.ollama
    # Para GPU NVIDIA (opcional, descomentar si tienes GPU)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Servicio MongoDB (COMENTADO - Usar MongoDB externo)
  # Descomentar si quieres levantar un servidor MongoDB local en Docker
  # mongodb:
  #   image: mongo:7.0
  #   container_name: mongodb-server
  #   ports:
  #     - "27017:27017"
  #   environment:
  #     - MONGO_INITDB_DATABASE=langchain_db
  #   volumes:
  #     # Persistir datos de MongoDB
  #     - mongodb_data:/data/db
  #     - mongodb_config:/data/configdb
  #   restart: unless-stopped
  #   healthcheck:
  #     test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 10s

  # Servicio LangChain App (Backend FastAPI)
  langchain-api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: langchain-app
    ports:
      - "8000:8000"
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - MODEL_NAME=llama3.2
      - PORT=8000
      - MAX_INPUT_LENGTH=10000
      - PYTHONUNBUFFERED=1
      - EMBEDDING_MODEL=nomic-embed-text
      # MongoDB Configuration - Actualizar con tu URI de MongoDB externo
      # Ejemplos: mongodb://localhost:27017, mongodb+srv://user:pass@cluster.mongodb.net
      # Para MongoDB local en host: mongodb://host.docker.internal:27017
      - MONGODB_URI=mongodb://host.docker.internal:27017
      - MONGODB_DATABASE=langchain_db
      - MONGODB_TIMEOUT=5000
      - MONGODB_MAX_POOL_SIZE=10


    command: python api_server.py
    volumes:
      # Montar codigo fuente para desarrollo
      - ./app:/app
      # Persistir base de datos ChromaDB
      - ./chroma_db:/app/chroma_db
    depends_on:
      ollama:
        condition: service_healthy
      ollama-init:
        condition: service_completed_successfully
      # mongodb:  # Comentado - usando MongoDB externo
      #   condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Setup Service (Pull data models automatically)
  ollama-init:
    image: ollama/ollama:latest
    container_name: ollama-puller
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=ollama:11434
    depends_on:
      ollama:
        condition: service_healthy
    entrypoint: /bin/sh
    command: -c "echo 'Esperando a Ollama...'; sleep 5; echo 'Descargando modelo nomic-embed-text...'; ollama pull nomic-embed-text; echo 'Descargando modelo llama3.2...'; ollama pull llama3.2; echo 'Modelos listos!'"

  # Servicio Web Frontend (React + Vite + Nginx)
  web:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: chatgpt-web
    ports:
      - "3000:80"
    depends_on:
      langchain-api:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  ollama_data:
    driver: local
  # mongodb_data:  # Comentado - usando MongoDB externo
  #   driver: local
  # mongodb_config:  # Comentado - usando MongoDB externo
  #   driver: local
